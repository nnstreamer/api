{
    "single" :
    {
        "framework" : "llamacpp",
        "model" : ["../tests/test_models/models/llama-2-7b-chat.Q2_K.gguf"],
        "custom" : "num_predict:32",
        "invoke_dynamic" : "true",
        "invoke_async" : "false"
    }
}
